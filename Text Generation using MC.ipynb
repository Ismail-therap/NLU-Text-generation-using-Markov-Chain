{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams(tokens,n):\n",
    "    sequences = [tokens[i:] for i in range(n)]\n",
    "    ngrams = [' '.join(ngram) for ngram in list(zip(*sequences))]\n",
    "    return ngrams, list(set(ngrams))\n",
    "\n",
    "\n",
    "def create_word_mapping(values_list):\n",
    "        values_list.append('<| unknown |>')\n",
    "        value2ind = {value: ind for ind, value in enumerate(values_list)}\n",
    "        ind2value = dict(enumerate(values_list))\n",
    "        return value2ind, ind2value\n",
    "\n",
    "def create_transition_prob_matrix(input_text,n):\n",
    "    \n",
    "    # n is for selecting the ngram\n",
    "    import re\n",
    "\n",
    "    punctuation_pad = '!?.,:-;'\n",
    "    punctuation_remove = '\"()_\\n'\n",
    "\n",
    "\n",
    "    content_preprocess = re.sub(r'(\\S)(\\n)(\\S)', r'\\1 \\2 \\3', input_text)\n",
    "    # Removing charecter like \\n\\n\n",
    "    content_preprocess = content_preprocess.translate(str.maketrans('', '', punctuation_remove))\n",
    "    # Considering , . as different charecter to be used as a state in the transition probability matri\n",
    "    content_preprocess = content_preprocess.translate(str.maketrans({key: ' {0} '.format(key) for key in punctuation_pad}))\n",
    "    # Removing extra space between words or charecters\n",
    "    content_preprocess = re.sub(' +', ' ', content_preprocess)\n",
    "    # remove leading and trailing whitespaces\n",
    "    content = content_preprocess.strip()\n",
    "    \n",
    "    tokens = content.split(' ')\n",
    "    token_dist = list(set(tokens))\n",
    "    \n",
    "\n",
    "    \n",
    "    ngram, ngram_dist = create_ngrams(tokens,n)\n",
    "    \n",
    "    token2ind, ind2token = create_word_mapping(token_dist) # distinct token\n",
    "    ngram2ind, ind2ngram = create_word_mapping(ngram_dist) # distinct ngram\n",
    "    \n",
    "    #tokens_ind = [token2ind[token] if token in token2ind.keys() else token2ind['<| unknown |>']\n",
    "     #                      for token in tokens]\n",
    "\n",
    "    \n",
    "    \n",
    "    row_ind, col_ind, values = [], [], []\n",
    "\n",
    "    for i in range(len(tokens[:-n])):\n",
    "        ngram = ' '.join(tokens[i:i + n])\n",
    "        ngram_ind = ngram2ind[ngram]\n",
    "        next_word_ind = token2ind[tokens[i + n]]\n",
    "\n",
    "        row_ind.extend([ngram_ind])\n",
    "        col_ind.extend([next_word_ind])\n",
    "        values.extend([1])\n",
    "\n",
    "    S = scipy.sparse.coo_matrix((values, (row_ind, col_ind)), shape=(len(ngram2ind), len(token2ind)))\n",
    "    \n",
    "    P = normalize(S, norm='l1', axis=1)\n",
    "    return P\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def powr(P,order):\n",
    "    import numpy as np\n",
    "    k = len(P)\n",
    "    M = np.identity(k)\n",
    "    for i in range(order):\n",
    "        M = np.dot(M,P)\n",
    "    return M\n",
    "\n",
    "\n",
    "def transition_probability_matrix(input_text,n,order):\n",
    "    if order == 1:\n",
    "        P = create_transition_prob_matrix(input_text,n)\n",
    "    else:\n",
    "        P = create_transition_prob_matrix(input_text,n)\n",
    "        P = P.toarray()\n",
    "        P = powr(P,order)\n",
    "        P = scipy.sparse.coo_matrix(P)\n",
    "        P = P.tocsr()\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/NMT MS/Spring 22/MATH 486/Project/game_of_thrones/game_of_thrones.txt'\n",
    "input_text = open(path, 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = create_transition_prob_matrix(input_text,n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115200, 13951)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13921)\t1.0\n",
      "  (1, 6689)\t1.0\n",
      "  (2, 9456)\t1.0\n",
      "  (3, 3461)\t0.14285714285714285\n",
      "  (3, 4542)\t0.2857142857142857\n",
      "  (3, 4867)\t0.14285714285714285\n",
      "  (3, 5648)\t0.14285714285714285\n",
      "  (3, 10308)\t0.14285714285714285\n",
      "  (3, 13921)\t0.14285714285714285\n",
      "  (4, 7052)\t1.0\n",
      "  (5, 4290)\t1.0\n",
      "  (6, 6248)\t1.0\n",
      "  (7, 10768)\t1.0\n",
      "  (8, 1074)\t0.5\n",
      "  (8, 5490)\t0.5\n",
      "  (9, 4015)\t1.0\n",
      "  (10, 12956)\t1.0\n",
      "  (11, 2547)\t0.25\n",
      "  (11, 7806)\t0.25\n",
      "  (11, 9163)\t0.25\n",
      "  (11, 12724)\t0.25\n",
      "  (12, 12363)\t1.0\n",
      "  (13, 4290)\t1.0\n",
      "  (14, 4290)\t1.0\n",
      "  (15, 6573)\t1.0\n",
      "  :\t:\n",
      "  (115180, 9114)\t1.0\n",
      "  (115181, 12964)\t1.0\n",
      "  (115182, 1611)\t0.3333333333333333\n",
      "  (115182, 6421)\t0.3333333333333333\n",
      "  (115182, 9223)\t0.3333333333333333\n",
      "  (115183, 12405)\t1.0\n",
      "  (115184, 12378)\t1.0\n",
      "  (115185, 12114)\t1.0\n",
      "  (115186, 810)\t1.0\n",
      "  (115187, 4290)\t1.0\n",
      "  (115188, 5665)\t1.0\n",
      "  (115189, 1611)\t0.6666666666666666\n",
      "  (115189, 13189)\t0.3333333333333333\n",
      "  (115190, 3463)\t0.25\n",
      "  (115190, 12974)\t0.25\n",
      "  (115190, 13189)\t0.25\n",
      "  (115190, 13690)\t0.25\n",
      "  (115191, 13189)\t1.0\n",
      "  (115192, 4290)\t1.0\n",
      "  (115193, 13921)\t1.0\n",
      "  (115194, 7161)\t1.0\n",
      "  (115195, 9280)\t1.0\n",
      "  (115196, 6248)\t1.0\n",
      "  (115197, 5648)\t1.0\n",
      "  (115198, 11586)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA = A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAA = powr(AA,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t5.800547028423785e-06\n",
      "  (0, 1)\t2.892887600369397e-06\n",
      "  (0, 2)\t2.912172250746355e-06\n",
      "  (0, 3)\t2.893310467910931e-06\n",
      "  (0, 4)\t8.736532207123111e-06\n",
      "  (0, 5)\t2.890071509263789e-06\n",
      "  (0, 6)\t5.5181241023822915e-05\n",
      "  (0, 7)\t1.157575649401192e-05\n",
      "  (0, 8)\t2.0351139118643596e-05\n",
      "  (0, 9)\t5.80613786618147e-06\n",
      "  (0, 10)\t2.9046754841551878e-06\n",
      "  (0, 11)\t0.00022074075064986302\n",
      "  (0, 12)\t5.820579645763569e-06\n",
      "  (0, 13)\t2.9035273450233724e-06\n",
      "  (0, 14)\t2.9005093829926192e-06\n",
      "  (0, 15)\t5.803789002168645e-06\n",
      "  (0, 16)\t5.865883825239653e-06\n",
      "  (0, 17)\t2.9075245750175298e-06\n",
      "  (0, 18)\t2.9113156660688543e-06\n",
      "  (0, 19)\t8.149556753622806e-05\n",
      "  (0, 20)\t2.9234815536531974e-06\n",
      "  (0, 21)\t2.9050668489093347e-06\n",
      "  (0, 22)\t2.892072758735196e-06\n",
      "  (0, 23)\t1.1601086130865655e-05\n",
      "  (0, 24)\t2.889527321445664e-06\n",
      "  :\t:\n",
      "  (13949, 13925)\t0.0007204370638158197\n",
      "  (13949, 13926)\t8.412959962844215e-05\n",
      "  (13949, 13927)\t2.9003776477341782e-06\n",
      "  (13949, 13928)\t1.4512472552583043e-05\n",
      "  (13949, 13929)\t2.8965773873283516e-06\n",
      "  (13949, 13930)\t1.4540634559695311e-05\n",
      "  (13949, 13931)\t5.824425054607101e-06\n",
      "  (13949, 13932)\t8.703937455227254e-06\n",
      "  (13949, 13933)\t9.583961523623436e-05\n",
      "  (13949, 13934)\t8.69958138227499e-06\n",
      "  (13949, 13935)\t2.8965773873283516e-06\n",
      "  (13949, 13936)\t2.323901919564932e-05\n",
      "  (13949, 13937)\t8.722820867279042e-06\n",
      "  (13949, 13938)\t2.8951050339588307e-06\n",
      "  (13949, 13939)\t0.00013898729522834858\n",
      "  (13949, 13940)\t1.1613302676127965e-05\n",
      "  (13949, 13941)\t2.9048363392343705e-06\n",
      "  (13949, 13942)\t2.8951050339588307e-06\n",
      "  (13949, 13943)\t5.8021794570378e-06\n",
      "  (13949, 13944)\t5.808995519945157e-06\n",
      "  (13949, 13945)\t5.80428378892761e-06\n",
      "  (13949, 13946)\t1.4527008652180423e-05\n",
      "  (13949, 13947)\t0.000770169760521457\n",
      "  (13949, 13948)\t3.1939059849318705e-05\n",
      "  (13949, 13949)\t1.1595410611413004e-05\n"
     ]
    }
   ],
   "source": [
    "print(scipy.sparse.coo_matrix(AAA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sentance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(input_text):\n",
    "    # n is for selecting the ngram\n",
    "    import re\n",
    "\n",
    "    punctuation_pad = '!?.,:-;'\n",
    "    punctuation_remove = '\"()_\\n'\n",
    "\n",
    "\n",
    "    content_preprocess = re.sub(r'(\\S)(\\n)(\\S)', r'\\1 \\2 \\3', input_text)\n",
    "    # Removing charecter like \\n\\n\n",
    "    content_preprocess = content_preprocess.translate(str.maketrans('', '', punctuation_remove))\n",
    "    # Considering , . as different charecter to be used as a state in the transition probability matri\n",
    "    content_preprocess = content_preprocess.translate(str.maketrans({key: ' {0} '.format(key) for key in punctuation_pad}))\n",
    "    # Removing extra space between words or charecters\n",
    "    content_preprocess = re.sub(' +', ' ', content_preprocess)\n",
    "    # remove leading and trailing whitespaces\n",
    "    content = content_preprocess.strip()\n",
    "    return content\n",
    "    \n",
    "\n",
    "\n",
    "def get_ngram(input_text,n):\n",
    "\n",
    "    content = pre_process(input_text)    \n",
    "    tokens = content.split(' ')\n",
    "    token_dist = list(set(tokens))\n",
    "    \n",
    "    sequences = [tokens[i:] for i in range(n)]\n",
    "    ngrams = [' '.join(ngram) for ngram in list(zip(*sequences))]\n",
    "    \n",
    "    \n",
    "    #ngram, ngram_dist = create_ngrams(tokens,n)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "def check_prefix(input_text,prefix,n):\n",
    "    prefix_list = prefix.split(' ')[-n:]\n",
    "    ngrams = get_ngram(input_text,n)\n",
    "    if len(prefix_list) < n:\n",
    "        warnings.warn(\n",
    "                'Prefix is too short, please provide prefix of length: %d. Random ngram used instead.' % n)\n",
    "        return np.random.choice(ngrams)\n",
    "    else:\n",
    "        prefix = ' '.join(prefix_list)\n",
    "        if prefix in ngrams:\n",
    "            return prefix\n",
    "        else:\n",
    "            warnings.warn(\n",
    "                    'Prefix is not included in ngrams of the model. Provide another prefix. Random ngram used instead.')\n",
    "            return np.random.choice(ngrams)\n",
    "\n",
    "        \n",
    "def return_next_word(input_text,prefix,n,order):\n",
    "    prefix = check_prefix(input_text,prefix,n)\n",
    "    content = pre_process(input_text)\n",
    " \n",
    "    \n",
    "    tokens = content.split(' ')\n",
    "    token_dist = list(set(tokens))\n",
    "    \n",
    "\n",
    "    \n",
    "    ngram, ngram_dist = create_ngrams(tokens,n)\n",
    "    token2ind, ind2token = create_word_mapping(token_dist) # distinct token\n",
    "    ngram2ind, ind2ngram = create_word_mapping(ngram_dist) # distinct ngram\n",
    "    \n",
    "    # Transition prob matrix\n",
    "    #transition_matrix_prob = create_transition_prob_matrix(input_text,n)\n",
    "    transition_matrix_prob = transition_probability_matrix(input_text,n,order)\n",
    "    prefix_ind = ngram2ind[prefix]\n",
    "    weights = transition_matrix_prob[prefix_ind].toarray()[0]\n",
    "    token_ind = np.random.choice(range(len(weights)), p=weights)\n",
    "    next_word = ind2token[token_ind]\n",
    "    return next_word\n",
    "\n",
    "def reverse_preprocess(text):\n",
    "    text_reverse = re.sub(r'\\s+([!?\"\\'().,;-])', r'\\1', text)\n",
    "    text_reverse = re.sub(' +', ' ', text_reverse)\n",
    "    return text_reverse\n",
    "\n",
    "\n",
    "\n",
    "def generate_sequence(input_text,prefix,n, k,order):\n",
    "    prefix = check_prefix(input_text,prefix,n)\n",
    "    sequence = prefix.split(' ')\n",
    "\n",
    "    for i in range(k):\n",
    "        next_word = return_next_word(input_text,prefix,n,order)\n",
    "        sequence.append(next_word)\n",
    "        prefix = ' '.join(sequence[-n:])\n",
    "\n",
    "    return reverse_preprocess(' '.join(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Snow. And her silver mockingbird cape and long trestle table'"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(input_text,prefix = \"Snow\",n = 1,k=10,order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sequence(input_text,prefix = \"Snow\",n = 1,k=10,order=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
